{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37aaa219-74b7-450f-bbbd-e8cd676b1ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jbhas\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c99a484-28f6-40a2-b7ff-aeff21e1d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from htru1 import HTRU1\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77d4cc4-17f8-4817-b849-d8de179fb1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443ea767-c47e-466b-94f2-562815e5b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation to apply\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb13fdfe-51b5-4964-8168-3cb6fb873c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the training and test datasets\n",
    "trainset = HTRU1(root='./data', train=True, download=True, transform=transform)\n",
    "testset = HTRU1(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa28ab21-694f-44e6-a3a0-b60eddff894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class counts and weights for sampling\n",
    "class_counts = [sum(1 for label in trainset.targets if label == 0),\n",
    "                sum(1 for label in trainset.targets if label == 1)]\n",
    "class_weights = [1.0 / count for count in class_counts]\n",
    "sample_weights = [class_weights[label] for label in trainset.targets]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "# Create data loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, sampler=sampler, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('nonpulsar', 'pulsar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11a582a3-38f6-41f3-918e-d43d07971c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network with increased complexity\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Adding more layers and filters\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        # Change kernel size to (2, 2) and stride to 1\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=2, stride=1, padding=1)  # Added another convolutional layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1_input_size = None  # Placeholder to calculate dynamically\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 512)  # Adjusted size to accommodate new filters\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))  # Added new convolutional layer\n",
    "\n",
    "        if self.fc1_input_size is None:\n",
    "            self.fc1_input_size = x.view(x.size(0), -1).size(1)\n",
    "            self.fc1 = nn.Linear(self.fc1_input_size, 512)\n",
    "            print(f\"Dynamically adjusted fc1 input size: {self.fc1_input_size}\")\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56831e49-5025-4058-9004-9e4cb5517856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbhas\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamically adjusted fc1 input size: 128\n",
      "Epoch 1, Train Loss: 0.1817, Val Loss: 0.1770\n",
      "Model saved at epoch 1\n",
      "Epoch 2, Train Loss: 0.0868, Val Loss: 0.0737\n",
      "Model saved at epoch 2\n",
      "Epoch 3, Train Loss: 0.0629, Val Loss: 0.0484\n",
      "Model saved at epoch 3\n",
      "Epoch 4, Train Loss: 0.0516, Val Loss: 0.0770\n",
      "Epoch 5, Train Loss: 0.0440, Val Loss: 0.0662\n",
      "Epoch 6, Train Loss: 0.0379, Val Loss: 0.0521\n",
      "Epoch 7, Train Loss: 0.0354, Val Loss: 0.0712\n",
      "Epoch 8, Train Loss: 0.0266, Val Loss: 0.0494\n",
      "Epoch 9, Train Loss: 0.0238, Val Loss: 0.0498\n",
      "Epoch 10, Train Loss: 0.0230, Val Loss: 0.0533\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Main training and evaluation code\n",
    "if __name__ == '__main__':\n",
    "    net = Net()\n",
    "    device = torch.device('cpu')\n",
    "    net.to(device)\n",
    "\n",
    "    pulsar_weight = 1\n",
    "    non_pulsar_weight = 1.5\n",
    "    class_weights = torch.tensor([non_pulsar_weight, pulsar_weight]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    # Learning Rate Scheduler: Reduce LR when validation loss plateaus\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    # Early stopping parameters\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 8\n",
    "    patience_counter = 0\n",
    "    nepoch = 10  # Maximum epochs\n",
    "\n",
    "    # Lists to track loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(nepoch):\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_losses.append(running_loss / len(trainloader))\n",
    "\n",
    "        # Validation step\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(testloader)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Check for early stopping and save the model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(net.state_dict(), 'best_model.pth')  # Save best model\n",
    "            print(f\"Model saved at epoch {epoch + 1}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "        # Step the scheduler based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    # Plotting learning curves\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Learning Curves')\n",
    "    plt.show()\n",
    "\n",
    "    # Load the best model for evaluation\n",
    "    net.load_state_dict(torch.load('best_model.pth', weights_only=True))\n",
    "    net.eval()  # Set to evaluation mode\n",
    "\n",
    "    # Evaluation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = [0, 0]\n",
    "    class_total = [0, 0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += (predicted[i] == label).item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    print(f'Accuracy of the network on the test images: {100 * correct / total:.2f}%')\n",
    "    for i in range(2):\n",
    "        print(f'Accuracy of {classes[i]}: {100 * class_correct[i] / class_total[i]:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa69d17-7a05-4db2-9419-de9566afa2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
